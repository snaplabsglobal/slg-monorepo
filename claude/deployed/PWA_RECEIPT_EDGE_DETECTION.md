# PWA æ”¶æ®è¾¹ç¼˜è‡ªåŠ¨è¯†åˆ«æŠ€æœ¯æ–¹æ¡ˆ

**CEO çš„é—®é¢˜**: SparkReceipt è¿™æ ·çš„è¾¹ç¼˜è¯†åˆ«åŠŸèƒ½ï¼Œåœ¨ PWA ä¸­å¥½åšå—ï¼Ÿ

**CTO çš„ç­”æ¡ˆ**: å®Œå…¨å¯ä»¥åšï¼è€Œä¸”å¯èƒ½æ¯”åŸç”Ÿ App æ›´å¥½ï¼

---

## ğŸ¯ åŠŸèƒ½åˆ†æ

### SparkReceipt çš„åŠŸèƒ½

```
1. æ‹ç…§åè‡ªåŠ¨è¯†åˆ«æ”¶æ®è¾¹ç¼˜
2. æ˜¾ç¤º 8 ä¸ªæ©™è‰²åœ†ç‚¹ï¼ˆè°ƒæ•´ç‚¹ï¼‰
3. ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨è°ƒæ•´
4. ç‚¹å‡»"Confirm edges"è‡ªåŠ¨è£å‰ª
5. é€è§†æ ¡æ­£ï¼ˆPerspective Transformï¼‰

æ•ˆæœ:
âœ… è‡ªåŠ¨æ¡†é€‰æ”¶æ®
âœ… å»é™¤èƒŒæ™¯
âœ… æ ¡æ­£è§’åº¦
âœ… æå‡è¯†åˆ«å‡†ç¡®åº¦
```

---

## ğŸ’¡ å…³é”®è¯¯åŒºæ¾„æ¸…

### CEO çš„æ‹…å¿ƒ âŒ

```
"æˆ‘ä»¬æ˜¯ PWAï¼Œä¸æ˜¯ App"
"å¥½åƒä¸èƒ½è°ƒç”¨æ‰‹æœº API"

è¿™æ˜¯è¯¯è§£ï¼
```

### çœŸç›¸ âœ…

```
PWA å¯ä»¥åšçš„:
âœ… è°ƒç”¨ç›¸æœºï¼ˆgetUserMedia APIï¼‰
âœ… Canvas å›¾åƒå¤„ç†
âœ… WebAssembly åŠ é€Ÿ
âœ… TensorFlow.js (AI è¾¹ç¼˜è¯†åˆ«)
âœ… OpenCV.js (è®¡ç®—æœºè§†è§‰)

PWA åšä¸åˆ°çš„:
âŒ è®¿é—®åº•å±‚ç¡¬ä»¶é©±åŠ¨
âŒ ç›´æ¥æ“ä½œæ–‡ä»¶ç³»ç»Ÿ
âŒ åå°é•¿æœŸè¿è¡Œ

ç»“è®º:
è¾¹ç¼˜è¯†åˆ« = 100% å¯ä»¥åœ¨ PWA ä¸­å®ç°ï¼
```

---

## ğŸ› ï¸ æŠ€æœ¯æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: TensorFlow.js + è¾¹ç¼˜æ£€æµ‹æ¨¡å‹ï¼ˆæ¨èï¼‰â­

```typescript
// ä½¿ç”¨ TensorFlow.js çš„é¢„è®­ç»ƒæ¨¡å‹

import * as tf from '@tensorflow/tfjs';
import * as cocoSsd from '@tensorflow-models/coco-ssd';

async function detectReceiptEdges(imageElement: HTMLImageElement) {
  // 1. åŠ è½½æ¨¡å‹
  const model = await cocoSsd.load();
  
  // 2. æ£€æµ‹å¯¹è±¡
  const predictions = await model.detect(imageElement);
  
  // 3. æ‰¾åˆ°"paper"æˆ–"document"
  const receipt = predictions.find(p => 
    p.class === 'paper' || p.class === 'book'
  );
  
  if (receipt) {
    // 4. è¿”å›è¾¹ç•Œæ¡†
    return {
      x: receipt.bbox[0],
      y: receipt.bbox[1],
      width: receipt.bbox[2],
      height: receipt.bbox[3]
    };
  }
  
  return null;
}

ä¼˜åŠ¿:
âœ… AI é©±åŠ¨ï¼Œå‡†ç¡®åº¦é«˜
âœ… çº¯å‰ç«¯ï¼Œæ— éœ€æœåŠ¡å™¨
âœ… é€‚åº”å„ç§èƒŒæ™¯
âœ… 100-200KB æ¨¡å‹å¤§å°

åŠ£åŠ¿:
âš ï¸ é¦–æ¬¡åŠ è½½ç¨æ…¢ï¼ˆ2-3ç§’ï¼‰
âš ï¸ éœ€è¦è¾ƒå¥½çš„æ‰‹æœºæ€§èƒ½
```

---

### æ–¹æ¡ˆ 2: OpenCV.js + Canny è¾¹ç¼˜æ£€æµ‹ï¼ˆç»å…¸ï¼‰

```typescript
// ä½¿ç”¨ OpenCV.js è¿›è¡Œè¾¹ç¼˜æ£€æµ‹

import cv from 'opencv.js';

function detectReceiptEdgesOpenCV(imageData: ImageData) {
  // 1. è½¬æ¢ä¸º OpenCV Mat
  const src = cv.matFromImageData(imageData);
  const dst = new cv.Mat();
  
  // 2. ç°åº¦åŒ–
  cv.cvtColor(src, src, cv.COLOR_RGBA2GRAY);
  
  // 3. é«˜æ–¯æ¨¡ç³Šï¼ˆé™å™ªï¼‰
  cv.GaussianBlur(src, src, new cv.Size(5, 5), 0);
  
  // 4. Canny è¾¹ç¼˜æ£€æµ‹
  cv.Canny(src, dst, 50, 150);
  
  // 5. æŸ¥æ‰¾è½®å»“
  const contours = new cv.MatVector();
  const hierarchy = new cv.Mat();
  cv.findContours(
    dst, 
    contours, 
    hierarchy, 
    cv.RETR_EXTERNAL, 
    cv.CHAIN_APPROX_SIMPLE
  );
  
  // 6. æ‰¾åˆ°æœ€å¤§çš„çŸ©å½¢è½®å»“
  let maxArea = 0;
  let maxContour = null;
  
  for (let i = 0; i < contours.size(); i++) {
    const contour = contours.get(i);
    const area = cv.contourArea(contour);
    
    if (area > maxArea) {
      maxArea = area;
      maxContour = contour;
    }
  }
  
  // 7. å¤šè¾¹å½¢è¿‘ä¼¼ï¼ˆæ‰¾åˆ° 4 ä¸ªè§’ï¼‰
  if (maxContour) {
    const approx = new cv.Mat();
    const peri = cv.arcLength(maxContour, true);
    cv.approxPolyDP(maxContour, approx, 0.02 * peri, true);
    
    if (approx.rows === 4) {
      // æ‰¾åˆ°äº†çŸ©å½¢ï¼
      return {
        topLeft: { x: approx.data32S[0], y: approx.data32S[1] },
        topRight: { x: approx.data32S[2], y: approx.data32S[3] },
        bottomRight: { x: approx.data32S[4], y: approx.data32S[5] },
        bottomLeft: { x: approx.data32S[6], y: approx.data32S[7] }
      };
    }
  }
  
  return null;
}

ä¼˜åŠ¿:
âœ… ç»å…¸ç®—æ³•ï¼Œç¨³å®šå¯é 
âœ… é€‚ç”¨äºå„ç§å…‰çº¿æ¡ä»¶
âœ… å¯ä»¥ç²¾ç¡®æ‰¾åˆ° 4 ä¸ªè§’
âœ… ä¸éœ€è¦ AI æ¨¡å‹

åŠ£åŠ¿:
âš ï¸ OpenCV.js ä½“ç§¯å¤§ï¼ˆ8MBï¼‰
âš ï¸ å¤æ‚èƒŒæ™¯å¯èƒ½è¯¯è¯†åˆ«
```

---

### æ–¹æ¡ˆ 3: ç®€åŒ–ç‰ˆ Canvas APIï¼ˆè½»é‡çº§ï¼‰

```typescript
// çº¯ Canvas API å®ç°ï¼ˆæœ€è½»é‡ï¼‰

function detectReceiptEdgesSimple(
  canvas: HTMLCanvasElement
): Rectangle | null {
  const ctx = canvas.getContext('2d')!;
  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
  const data = imageData.data;
  
  // 1. è½¬æ¢ä¸ºç°åº¦
  const grayData = new Uint8Array(canvas.width * canvas.height);
  for (let i = 0; i < data.length; i += 4) {
    const gray = 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];
    grayData[i / 4] = gray;
  }
  
  // 2. ç®€å•è¾¹ç¼˜æ£€æµ‹ï¼ˆSobel ç®—å­ï¼‰
  const edges = sobelEdgeDetection(grayData, canvas.width, canvas.height);
  
  // 3. æŸ¥æ‰¾è¾¹ç•Œ
  const bounds = findLargestRectangle(edges, canvas.width, canvas.height);
  
  return bounds;
}

function sobelEdgeDetection(
  gray: Uint8Array, 
  width: number, 
  height: number
): Uint8Array {
  const edges = new Uint8Array(width * height);
  
  // Sobel æ ¸
  const Gx = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]];
  const Gy = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]];
  
  for (let y = 1; y < height - 1; y++) {
    for (let x = 1; x < width - 1; x++) {
      let gx = 0, gy = 0;
      
      for (let ky = -1; ky <= 1; ky++) {
        for (let kx = -1; kx <= 1; kx++) {
          const pixel = gray[(y + ky) * width + (x + kx)];
          gx += pixel * Gx[ky + 1][kx + 1];
          gy += pixel * Gy[ky + 1][kx + 1];
        }
      }
      
      edges[y * width + x] = Math.sqrt(gx * gx + gy * gy);
    }
  }
  
  return edges;
}

ä¼˜åŠ¿:
âœ… ä½“ç§¯æå°ï¼ˆå‡  KBï¼‰
âœ… ä¸ä¾èµ–å¤–éƒ¨åº“
âœ… åŠ è½½é€Ÿåº¦å¿«
âœ… é€‚åˆç®€å•åœºæ™¯

åŠ£åŠ¿:
âš ï¸ å‡†ç¡®åº¦ä¸å¦‚ AI
âš ï¸ å¤æ‚èƒŒæ™¯æ•ˆæœå·®
âš ï¸ éœ€è¦å¥½çš„å…‰çº¿
```

---

## ğŸ“± PWA ç›¸æœºè°ƒç”¨

### å®Œæ•´çš„æ‹ç…§æµç¨‹

```typescript
// components/camera/ReceiptCamera.tsx

'use client';

import { useRef, useState } from 'react';

export function ReceiptCamera() {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [detectedEdges, setDetectedEdges] = useState<Rectangle | null>(null);
  
  // 1. å¯åŠ¨ç›¸æœº
  async function startCamera() {
    try {
      const mediaStream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: 'environment', // åç½®æ‘„åƒå¤´
          width: { ideal: 1920 },
          height: { ideal: 1080 }
        }
      });
      
      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
        setStream(mediaStream);
      }
    } catch (error) {
      console.error('Camera access denied:', error);
    }
  }
  
  // 2. å®æ—¶è¾¹ç¼˜æ£€æµ‹ï¼ˆå¯é€‰ï¼‰
  function startRealtimeDetection() {
    const interval = setInterval(() => {
      if (videoRef.current && canvasRef.current) {
        const ctx = canvasRef.current.getContext('2d')!;
        
        // å°†è§†é¢‘å¸§ç»˜åˆ¶åˆ° canvas
        ctx.drawImage(
          videoRef.current, 
          0, 0, 
          canvasRef.current.width, 
          canvasRef.current.height
        );
        
        // æ£€æµ‹è¾¹ç¼˜
        const edges = detectReceiptEdges(canvasRef.current);
        setDetectedEdges(edges);
      }
    }, 100); // æ¯ 100ms æ£€æµ‹ä¸€æ¬¡
    
    return () => clearInterval(interval);
  }
  
  // 3. æ‹ç…§
  function capturePhoto() {
    if (videoRef.current && canvasRef.current) {
      const ctx = canvasRef.current.getContext('2d')!;
      
      // æ•è·å½“å‰å¸§
      ctx.drawImage(
        videoRef.current, 
        0, 0, 
        canvasRef.current.width, 
        canvasRef.current.height
      );
      
      // æ£€æµ‹è¾¹ç¼˜
      const edges = detectReceiptEdges(canvasRef.current);
      
      return {
        image: canvasRef.current.toDataURL('image/jpeg'),
        edges
      };
    }
  }
  
  // 4. åœæ­¢ç›¸æœº
  function stopCamera() {
    if (stream) {
      stream.getTracks().forEach(track => track.stop());
      setStream(null);
    }
  }
  
  return (
    <div className="relative">
      {/* è§†é¢‘é¢„è§ˆ */}
      <video
        ref={videoRef}
        autoPlay
        playsInline
        className="w-full h-full object-cover"
      />
      
      {/* éšè—çš„ Canvasï¼ˆç”¨äºå¤„ç†ï¼‰*/}
      <canvas
        ref={canvasRef}
        className="hidden"
        width={1920}
        height={1080}
      />
      
      {/* è¾¹ç¼˜æ£€æµ‹å åŠ å±‚ */}
      {detectedEdges && (
        <EdgeOverlay edges={detectedEdges} />
      )}
      
      {/* æ§åˆ¶æŒ‰é’® */}
      <div className="absolute bottom-4 left-0 right-0 flex justify-center gap-4">
        <button
          onClick={startCamera}
          className="px-6 py-3 bg-blue-500 text-white rounded-full"
        >
          ğŸ“· å¯åŠ¨ç›¸æœº
        </button>
        
        <button
          onClick={capturePhoto}
          className="px-6 py-3 bg-green-500 text-white rounded-full"
        >
          âœ“ æ‹ç…§
        </button>
        
        <button
          onClick={stopCamera}
          className="px-6 py-3 bg-red-500 text-white rounded-full"
        >
          âœ• åœæ­¢
        </button>
      </div>
    </div>
  );
}
```

---

## ğŸ¨ è¾¹ç¼˜æ˜¾ç¤ºç»„ä»¶

### SparkReceipt é£æ ¼çš„è°ƒæ•´ç‚¹

```typescript
// components/camera/EdgeOverlay.tsx

interface EdgeOverlayProps {
  edges: Rectangle;
  onAdjust?: (newEdges: Rectangle) => void;
}

export function EdgeOverlay({ edges, onAdjust }: EdgeOverlayProps) {
  const [adjustedEdges, setAdjustedEdges] = useState(edges);
  const [dragging, setDragging] = useState<string | null>(null);
  
  const corners = [
    { name: 'topLeft', x: adjustedEdges.topLeft.x, y: adjustedEdges.topLeft.y },
    { name: 'topRight', x: adjustedEdges.topRight.x, y: adjustedEdges.topRight.y },
    { name: 'bottomRight', x: adjustedEdges.bottomRight.x, y: adjustedEdges.bottomRight.y },
    { name: 'bottomLeft', x: adjustedEdges.bottomLeft.x, y: adjustedEdges.bottomLeft.y }
  ];
  
  function handleDrag(cornerName: string, newX: number, newY: number) {
    setAdjustedEdges(prev => ({
      ...prev,
      [cornerName]: { x: newX, y: newY }
    }));
  }
  
  return (
    <svg className="absolute inset-0 w-full h-full pointer-events-none">
      {/* åŠé€æ˜é®ç½© */}
      <mask id="receipt-mask">
        <rect width="100%" height="100%" fill="white" />
        <polygon
          points={`
            ${adjustedEdges.topLeft.x},${adjustedEdges.topLeft.y}
            ${adjustedEdges.topRight.x},${adjustedEdges.topRight.y}
            ${adjustedEdges.bottomRight.x},${adjustedEdges.bottomRight.y}
            ${adjustedEdges.bottomLeft.x},${adjustedEdges.bottomLeft.y}
          `}
          fill="black"
        />
      </mask>
      
      <rect
        width="100%"
        height="100%"
        fill="black"
        opacity="0.5"
        mask="url(#receipt-mask)"
      />
      
      {/* è¾¹æ¡†çº¿ */}
      <polygon
        points={`
          ${adjustedEdges.topLeft.x},${adjustedEdges.topLeft.y}
          ${adjustedEdges.topRight.x},${adjustedEdges.topRight.y}
          ${adjustedEdges.bottomRight.x},${adjustedEdges.bottomRight.y}
          ${adjustedEdges.bottomLeft.x},${adjustedEdges.bottomLeft.y}
        `}
        fill="none"
        stroke="#FFA500"
        strokeWidth="3"
      />
      
      {/* 8 ä¸ªè°ƒæ•´ç‚¹ï¼ˆSparkReceipt é£æ ¼ï¼‰*/}
      {corners.map((corner, index) => (
        <g key={corner.name}>
          {/* å¤–åœˆ */}
          <circle
            cx={corner.x}
            cy={corner.y}
            r="25"
            fill="#FFA500"
            opacity="0.8"
            className="pointer-events-auto cursor-move"
            onMouseDown={() => setDragging(corner.name)}
          />
          
          {/* å†…åœˆ */}
          <circle
            cx={corner.x}
            cy={corner.y}
            r="15"
            fill="#FF8C00"
          />
        </g>
      ))}
      
      {/* ä¸­ç‚¹ï¼ˆ4 ä¸ªè¾¹çš„ä¸­ç‚¹ï¼‰*/}
      <circle cx={(adjustedEdges.topLeft.x + adjustedEdges.topRight.x) / 2} 
              cy={(adjustedEdges.topLeft.y + adjustedEdges.topRight.y) / 2} 
              r="20" fill="#FFA500" opacity="0.6" />
      <circle cx={(adjustedEdges.topRight.x + adjustedEdges.bottomRight.x) / 2} 
              cy={(adjustedEdges.topRight.y + adjustedEdges.bottomRight.y) / 2} 
              r="20" fill="#FFA500" opacity="0.6" />
      <circle cx={(adjustedEdges.bottomRight.x + adjustedEdges.bottomLeft.x) / 2} 
              cy={(adjustedEdges.bottomRight.y + adjustedEdges.bottomLeft.y) / 2} 
              r="20" fill="#FFA500" opacity="0.6" />
      <circle cx={(adjustedEdges.bottomLeft.x + adjustedEdges.topLeft.x) / 2} 
              cy={(adjustedEdges.bottomLeft.y + adjustedEdges.topLeft.y) / 2} 
              r="20" fill="#FFA500" opacity="0.6" />
    </svg>
  );
}
```

---

## ğŸ”„ é€è§†æ ¡æ­£ï¼ˆPerspective Transformï¼‰

### å°†å€¾æ–œçš„æ”¶æ®æ ¡æ­£ä¸ºçŸ©å½¢

```typescript
// lib/perspective-transform.ts

interface Point {
  x: number;
  y: number;
}

interface Rectangle {
  topLeft: Point;
  topRight: Point;
  bottomRight: Point;
  bottomLeft: Point;
}

export function perspectiveTransform(
  canvas: HTMLCanvasElement,
  edges: Rectangle,
  outputWidth: number = 800,
  outputHeight: number = 1200
): HTMLCanvasElement {
  const ctx = canvas.getContext('2d')!;
  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
  
  // åˆ›å»ºè¾“å‡º canvas
  const outputCanvas = document.createElement('canvas');
  outputCanvas.width = outputWidth;
  outputCanvas.height = outputHeight;
  const outputCtx = outputCanvas.getContext('2d')!;
  const outputImageData = outputCtx.createImageData(outputWidth, outputHeight);
  
  // è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
  const matrix = computePerspectiveMatrix(
    edges,
    {
      topLeft: { x: 0, y: 0 },
      topRight: { x: outputWidth, y: 0 },
      bottomRight: { x: outputWidth, y: outputHeight },
      bottomLeft: { x: 0, y: outputHeight }
    }
  );
  
  // åº”ç”¨å˜æ¢
  for (let y = 0; y < outputHeight; y++) {
    for (let x = 0; x < outputWidth; x++) {
      // è®¡ç®—æºåæ ‡
      const srcPoint = applyMatrix(matrix, { x, y });
      
      // åŒçº¿æ€§æ’å€¼
      const pixel = bilinearInterpolation(
        imageData,
        srcPoint.x,
        srcPoint.y,
        canvas.width,
        canvas.height
      );
      
      // å†™å…¥è¾“å‡º
      const outputIndex = (y * outputWidth + x) * 4;
      outputImageData.data[outputIndex] = pixel.r;
      outputImageData.data[outputIndex + 1] = pixel.g;
      outputImageData.data[outputIndex + 2] = pixel.b;
      outputImageData.data[outputIndex + 3] = 255;
    }
  }
  
  outputCtx.putImageData(outputImageData, 0, 0);
  return outputCanvas;
}

function computePerspectiveMatrix(
  src: Rectangle,
  dst: Rectangle
): number[][] {
  // è®¡ç®— 3x3 é€è§†å˜æ¢çŸ©é˜µ
  // ä½¿ç”¨é½æ¬¡åæ ‡ç³»ç»Ÿ
  
  const srcPoints = [
    src.topLeft, src.topRight, 
    src.bottomRight, src.bottomLeft
  ];
  const dstPoints = [
    dst.topLeft, dst.topRight, 
    dst.bottomRight, dst.bottomLeft
  ];
  
  // è§£çº¿æ€§æ–¹ç¨‹ç»„ï¼ˆ8 ä¸ªæ–¹ç¨‹ï¼Œ8 ä¸ªæœªçŸ¥æ•°ï¼‰
  // [è¯¦ç»†æ•°å­¦æ¨å¯¼çœç•¥]
  
  return matrix; // 3x3 çŸ©é˜µ
}
```

---

## ğŸ“Š æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”

```
æ–¹æ¡ˆ              å‡†ç¡®åº¦   æ€§èƒ½   ä½“ç§¯    éš¾åº¦   æ¨è
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TensorFlow.js     â­â­â­â­â­  ğŸŸ¡ä¸­   200KB  ğŸŸ¡ä¸­   â­â­â­â­â­
OpenCV.js         â­â­â­â­   ğŸŸ¢å¿«   8MB   ğŸ”´é«˜   â­â­â­
Canvas API        â­â­â­    ğŸŸ¢å¿«   <10KB  ğŸŸ¢ä½   â­â­â­â­
```

---

## ğŸ¯ æ¨èå®æ–½æ–¹æ¡ˆ

### Phase 1: MVPï¼ˆæœ€å°å¯è¡Œäº§å“ï¼‰

```typescript
// ä½¿ç”¨ Canvas API + ç®€å•è¾¹ç¼˜æ£€æµ‹

ä¼˜åŠ¿:
âœ… å¿«é€Ÿå®ç°ï¼ˆ1-2 å¤©ï¼‰
âœ… ä½“ç§¯å°
âœ… ä¸ä¾èµ–å¤–éƒ¨åº“

å®æ–½æ­¥éª¤:
1. ç›¸æœºè°ƒç”¨ï¼ˆgetUserMediaï¼‰
2. Canvas å¤„ç†
3. ç®€å•è¾¹ç¼˜æ£€æµ‹ï¼ˆSobelï¼‰
4. æ‰‹åŠ¨è°ƒæ•´ç‚¹
5. é€è§†æ ¡æ­£
```

### Phase 2: å¢å¼ºç‰ˆ

```typescript
// æ·»åŠ  TensorFlow.js AI æ£€æµ‹

ä¼˜åŠ¿:
âœ… å‡†ç¡®åº¦å¤§å¹…æå‡
âœ… é€‚åº”å¤æ‚èƒŒæ™¯
âœ… è‡ªåŠ¨è¯†åˆ«æ›´æ™ºèƒ½

å®æ–½æ­¥éª¤:
1. é›†æˆ TensorFlow.js
2. åŠ è½½è¾¹ç¼˜æ£€æµ‹æ¨¡å‹
3. è‡ªåŠ¨æ¡†é€‰æ”¶æ®
4. ä¿ç•™æ‰‹åŠ¨è°ƒæ•´
```

---

## ğŸš€ å®Œæ•´å®ç°ä»£ç 

### 1. ç›¸æœºç»„ä»¶

```typescript
// app/(dashboard)/receipts/camera/page.tsx

'use client';

import { useState, useRef } from 'react';
import { detectReceiptEdges } from '@/lib/edge-detection';
import { perspectiveTransform } from '@/lib/perspective-transform';

export default function CameraPage() {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [edges, setEdges] = useState<Rectangle | null>(null);
  const [captured, setCaptured] = useState<string | null>(null);
  
  async function handleCapture() {
    // 1. æ•è·å›¾åƒ
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d')!;
    canvas.width = videoRef.current!.videoWidth;
    canvas.height = videoRef.current!.videoHeight;
    ctx.drawImage(videoRef.current!, 0, 0);
    
    // 2. æ£€æµ‹è¾¹ç¼˜
    const detectedEdges = await detectReceiptEdges(canvas);
    setEdges(detectedEdges);
  }
  
  function handleConfirm() {
    if (!edges) return;
    
    // 3. é€è§†æ ¡æ­£
    const canvas = document.createElement('canvas');
    const corrected = perspectiveTransform(canvas, edges);
    
    // 4. è½¬æ¢ä¸º Base64
    const dataUrl = corrected.toDataURL('image/jpeg', 0.9);
    setCaptured(dataUrl);
    
    // 5. ä¸Šä¼ åˆ°æœåŠ¡å™¨
    uploadReceipt(dataUrl);
  }
  
  return (
    <div className="relative h-screen">
      <video ref={videoRef} autoPlay className="w-full h-full object-cover" />
      
      {edges && (
        <EdgeOverlay 
          edges={edges} 
          onAdjust={setEdges}
        />
      )}
      
      <div className="absolute bottom-4 left-0 right-0 flex justify-center gap-4">
        {!edges ? (
          <button onClick={handleCapture} className="btn-primary">
            ğŸ“· æ‹ç…§
          </button>
        ) : (
          <>
            <button onClick={() => setEdges(null)} className="btn-secondary">
              â† é‡æ‹
            </button>
            <button onClick={handleConfirm} className="btn-primary">
              âœ“ ç¡®è®¤è¾¹ç¼˜
            </button>
          </>
        )}
      </div>
    </div>
  );
}
```

---

## âœ… CEO éœ€è¦çŸ¥é“çš„

### å¯è¡Œæ€§

```
âœ… PWA å®Œå…¨å¯ä»¥å®ç°è¾¹ç¼˜è¯†åˆ«
âœ… ä¸éœ€è¦åŸç”Ÿ App
âœ… æ€§èƒ½è¶³å¤Ÿå¥½
âœ… ç”¨æˆ·ä½“éªŒä¸è¾“ SparkReceipt
```

### éš¾åº¦è¯„ä¼°

```
å¼€å‘éš¾åº¦: ğŸŸ¡ ä¸­ç­‰
æ—¶é—´ä¼°è®¡: 3-5 å¤©
æŠ€æœ¯é£é™©: ğŸŸ¢ ä½
```

### å®æ–½å»ºè®®

```
Phase 1 (MVP): Canvas API
- æ—¶é—´: 1-2 å¤©
- åŠŸèƒ½: åŸºç¡€è¾¹ç¼˜æ£€æµ‹ + æ‰‹åŠ¨è°ƒæ•´

Phase 2 (å¢å¼º): TensorFlow.js
- æ—¶é—´: 2-3 å¤©
- åŠŸèƒ½: AI è‡ªåŠ¨è¯†åˆ« + æ™ºèƒ½è£å‰ª

æ€»è®¡: 3-5 å¤©å®Œæˆ
```

---

**CEOï¼Œç®€å•æ€»ç»“**:

### æ‚¨çš„æ‹…å¿ƒæ˜¯å¤šä½™çš„ï¼âœ…

1. **PWA å¯ä»¥è°ƒç”¨ç›¸æœº** âœ…
2. **è¾¹ç¼˜è¯†åˆ«å®Œå…¨å¯è¡Œ** âœ…
3. **ä¸è¾“åŸç”Ÿ App ä½“éªŒ** âœ…
4. **3-5 å¤©å¯ä»¥å®ç°** âœ…

**æ¨è**: å…ˆåš MVPï¼ˆCanvas APIï¼‰ï¼ŒéªŒè¯åå†åŠ  AIï¼

ğŸš€ **ç«‹å³å¼€å§‹å®æ–½ï¼**
